# Awesome-CLIP-TTA
## Description
This repository compiles papers on Test-Time Adaptation algorithms for the CLIP model.
## 2025
## 2024
`DART`[AAAI'2024]**DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29320)][[code](https://github.com/zhoujiahuan1991/AAAI2024-DART)]
`ADAPROMPT`[AAAI'2024]**Robust Test-Time Adaptation for Zero-Shot Prompt Tuning**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29611)][[code](https://github.com/zhangdingchu/Adaprompt)]  
`TDA`[CVPR'2024]**Efficient Test-Time Adaptation of Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Karmanov_Efficient_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2024_paper.pdf)][[code](https://github.com/kdiAAA/TDA)]  
`IST`[CVPR'2024]**Improved Self-Training for Test-Time Adaptation**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_Improved_Self-Training_for_Test-Time_Adaptation_CVPR_2024_paper.pdf)][[code](https://github.com/JingInAI/IST4TTA)]  
`MTA`[CVPR'2024]**On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zanella_On_the_Test-Time_Zero-Shot_Generalization_of_Vision-Language_Models_Do_We_CVPR_2024_paper.pdf)][[code](https://github.com/MaxZanella/MTA)]  
`C-TPT`[[ICLR'2024]]**C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion**[[paper](https://openreview.net/pdf?id=jzzEHTBFOT)][[code](https://github.com/hee-suk-yoon/C-TPT)]  
`RLCF`[ICLR'2024]**Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models**[[paper](https://proceedings.iclr.cc/paper_files/paper/2024/file/0faa4bc5f522076947a030273629d4fe-Paper-Conference.pdf)][[code](https://github.com/mzhaoshuai/RLCF)]  
`SCP`[ACM MM'2024]**Towards Robustness Prompt Tuning with Fully Test-Time Adaptation for CLIPâ€™s Zero-Shot Generalization**[[paper]([https://openreview.net/pdf?id=BVFAVis7ui](https://dl.acm.org/doi/pdf/10.1145/3664647.3681213))][[code](https://github.com/ranwang1123/SCP)]  
`DPE`[NeurIPS'2024]**Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/38b787fc530d0b31825827e2cc306656-Paper-Conference.pdf)][[code](https://github.com/zhangce01/dpe-clip)]   
`HisTPT`[NeurIPS'2024]**Historical Test-time Prompt Tuning for Vision Foundation Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/178ae4ba29022eb7bf509c2e27bc8ab8-Paper-Conference.pdf)]   
`ZERO`[NeurIPS'2024]**Frustratingly Easy Test-Time Adaptation of Vision-Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/e92cb6f981a2cacb2a710ecaa0d7b141-Paper-Conference.pdf)][[code](https://github.com/FarinaMatteo/zero)]  
`WATT`[NeurIPS'2024]**WATT: Weight Average Test-Time Adaptation of CLIP**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/55d16334943f8728073e17139e5baa3d-Paper-Conference.pdf)][[code](https://github.com/Mehrdad-Noori/WATT)]  
## 2023
`DiffTPT`[ICCV'2023]**Diverse Data Augmentation with Diffusions for Effective Test-time Prompt Tuning**[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.pdf)][[code](https://github.com/chunmeifeng/DiffTPT)]
`SwapPrompt`[NeurIPS'2023]**SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/cdd0640218a27e9e2c0e52e324e25db0-Paper-Conference.pdf)]
## 2022
`TPT`[NeurIPS'2022]**Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models**[[paper](https://openreview.net/pdf?id=e8PVEkSa4Fq)][[code](https://github.com/azshue/TPT)]
