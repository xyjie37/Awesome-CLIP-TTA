# Awesome-CLIP-TTA
## Description
This repository compiles papers on Test-Time Adaptation algorithms for the CLIP model.
## 2025
`BCA`[CVPR'2025]**Bayesian Test-Time Adaptation for Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Bayesian_Test-Time_Adaptation_for_Vision-Language_Models_CVPR_2025_paper.pdf)][[code](https://github.com/cuishuang99/BayesTTA)]    
`COSMIC`[CVPR'2025]**COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation**[[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_COSMIC_Clique-Oriented_Semantic_Multi-space_Integration_for_Robust_CLIP_Test-Time_Adaptation_CVPR_2025_paper.pdf)][code](https://github.com/hf618/COSMIC)]  
`StatA`[CVPR'2025]**Realistic Test-Time Adaptation of Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Zanella_Realistic_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2025_paper.pdf)][[code](https://github.com/MaxZanella/StatA)]    
`TAPT`[CVPR'2025]**TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TAPT_Test-Time_Adversarial_Prompt_Tuning_for_Robust_Inference_in_Vision-Language_CVPR_2025_paper.pdf)][[code](https://github.com/xinwong/TAPT)]    
`ECALP`[ICLR'2025]**Efficient and Context-Aware Label Propagation for Zero-/Few-Shot Training-Free Adaptation of Vision-Language Model**[[paper](https://openreview.net/pdf?id=D10yarGQNk)][[code](https://github.com/Yushu-Li/ECALP)]   
`ZS-NTTA`[ICLR'2025]**Noisy Test-Time Adaptation in Vision-Language Models**[[paper](https://openreview.net/pdf?id=iylpeTI0Ql)][[code](https://github.com/tmlr-group/ZS-NTTA)]
`CRG`[ICME'2025]**Mitigating Cache Noise in Test-Time Adaptation for Large Vision-Language Models**[[paper](https://arxiv.org/pdf/2503.18334)]    
`CLIPARTT`[WACV'2025]**CLIPArTT: Adaptation of CLIP to New Domains at Test Time**[[paper](https://openaccess.thecvf.com/content/WACV2025/papers/Hakim_CLIPArTT_Adaptation_of_CLIP_to_New_Domains_at_Test_Time_WACV_2025_paper.pdf)][[code](https://github.com/dosowiechi/CLIPArTT)]   
`TPS`[WACV'2025]**Just Shift It: Test-Time Prototype Shifting for Zero-Shot Generalization with Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/WACV2025/papers/Sui_Just_Shift_It_Test-Time_Prototype_Shifting_for_Zero-Shot_Generalization_with_WACV_2025_paper.pdf)][[code](https://github.com/elaine-sui/TPS)]   
`TTL`[WACV'2025]**Test-Time Low Rank Adaptation via Confidence Maximization for Zero-Shot Generalization of Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/WACV2025/papers/Imam_Test-Time_Low_Rank_Adaptation_via_Confidence_Maximization_for_Zero-Shot_Generalization_WACV_2025_paper.pdf)][[code](https://github.com/Razaimam45/TTL-Test-Time-Low-Rank-Adaptation)]   
`ETTA`[BMVC'2025]**ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates**[[paper](https://arxiv.org/pdf/2508.05898)][[code](https://github.com/hamidreza-dastmalchi/ETTA)]`ETTA`[BMVC'2025]**ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates**[[paper](https://arxiv.org/pdf/2508.05898)][[code](https://github.com/hamidreza-dastmalchi/ETTA)]
## 2024
`DART`[AAAI'2024]**DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29320)][[code](https://github.com/zhoujiahuan1991/AAAI2024-DART)]
`ADAPROMPT`[AAAI'2024]**Robust Test-Time Adaptation for Zero-Shot Prompt Tuning**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29611)][[code](https://github.com/zhangdingchu/Adaprompt)]  
`TDA`[CVPR'2024]**Efficient Test-Time Adaptation of Vision-Language Models**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Karmanov_Efficient_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2024_paper.pdf)][[code](https://github.com/kdiAAA/TDA)]  
`IST`[CVPR'2024]**Improved Self-Training for Test-Time Adaptation**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_Improved_Self-Training_for_Test-Time_Adaptation_CVPR_2024_paper.pdf)][[code](https://github.com/JingInAI/IST4TTA)]  
`MTA`[CVPR'2024]**On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zanella_On_the_Test-Time_Zero-Shot_Generalization_of_Vision-Language_Models_Do_We_CVPR_2024_paper.pdf)][[code](https://github.com/MaxZanella/MTA)]  
`C-TPT`[[ICLR'2024]]**C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion**[[paper](https://openreview.net/pdf?id=jzzEHTBFOT)][[code](https://github.com/hee-suk-yoon/C-TPT)]  
`RLCF`[ICLR'2024]**Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models**[[paper](https://proceedings.iclr.cc/paper_files/paper/2024/file/0faa4bc5f522076947a030273629d4fe-Paper-Conference.pdf)][[code](https://github.com/mzhaoshuai/RLCF)]  
`SCP`[ACM MM'2024]**Towards Robustness Prompt Tuning with Fully Test-Time Adaptation for CLIPâ€™s Zero-Shot Generalization**[[paper]([https://openreview.net/pdf?id=BVFAVis7ui](https://dl.acm.org/doi/pdf/10.1145/3664647.3681213))][[code](https://github.com/ranwang1123/SCP)]  
`BoostAdapter`[NeurIPS'2024]**BoostAdapter: Improving Vision-Language Test-Time Adaptation via Regional Bootstrapping**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/7d60bfd8458b67acbbaf18b892338d00-Paper-Conference.pdf)][[code](https://github.com/taolinzhang/BoostAdapter)]   
`DPE`[NeurIPS'2024]**Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/38b787fc530d0b31825827e2cc306656-Paper-Conference.pdf)][[code](https://github.com/zhangce01/dpe-clip)]   
`HisTPT`[NeurIPS'2024]**Historical Test-time Prompt Tuning for Vision Foundation Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/178ae4ba29022eb7bf509c2e27bc8ab8-Paper-Conference.pdf)]   
`ZERO`[NeurIPS'2024]**Frustratingly Easy Test-Time Adaptation of Vision-Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/e92cb6f981a2cacb2a710ecaa0d7b141-Paper-Conference.pdf)][[code](https://github.com/FarinaMatteo/zero)]  
`WATT`[NeurIPS'2024]**WATT: Weight Average Test-Time Adaptation of CLIP**[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/55d16334943f8728073e17139e5baa3d-Paper-Conference.pdf)][[code](https://github.com/Mehrdad-Noori/WATT)]  
## 2023
`DiffTPT`[ICCV'2023]**Diverse Data Augmentation with Diffusions for Effective Test-time Prompt Tuning**[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.pdf)][[code](https://github.com/chunmeifeng/DiffTPT)]
`PromptAlign`[NeurIPS'2023]**Align Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization**[[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/fe8debfd5a36ada52e038c8b2078b2ce-Paper-Conference.pdf)][[code](https://github.com/jameelhassan/PromptAlign)]   
`SwapPrompt`[NeurIPS'2023]**SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models**[[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/cdd0640218a27e9e2c0e52e324e25db0-Paper-Conference.pdf)]
## 2022
`TPT`[NeurIPS'2022]**Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models**[[paper](https://openreview.net/pdf?id=e8PVEkSa4Fq)][[code](https://github.com/azshue/TPT)]
